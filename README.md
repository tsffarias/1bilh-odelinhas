# Um Bilh√£o de Linhas: Desafio de Processamento de Dados com Python

## Diagrama

![arquitetura](/img/arquitetura_1.1.png)

## Introdu√ß√£o

O objetivo deste projeto √© demonstrar como processar eficientemente um arquivo de dados massivo contendo 1 bilh√£o de linhas (~15GB), especificamente para calcular estat√≠sticas (Incluindo agrega√ß√£o e ordena√ß√£o que s√£o opera√ß√µes pesadas) utilizando Python. 

Este desafio foi inspirado no [The One Billion Row Challenge](https://github.com/gunnarmorling/1brc), originalmente proposto para Java.

O arquivo de dados consiste em medi√ß√µes de temperatura de v√°rias esta√ß√µes meteorol√≥gicas. Cada registro segue o formato `<string: nome da esta√ß√£o>;<double: medi√ß√£o>`, com a temperatura sendo apresentada com precis√£o de uma casa decimal.

Aqui est√£o dez linhas de exemplo do arquivo:

```
Hamburg;12.0
Bulawayo;8.9
Palembang;38.8
St. Johns;15.2
Cracow;12.6
Bridgetown;26.9
Istanbul;6.2
Roseau;34.4
Conakry;31.2
Istanbul;23.0
```

O desafio √© desenvolver um programa Python capaz de ler esse arquivo e calcular a temperatura m√≠nima, m√©dia (arredondada para uma casa decimal) e m√°xima para cada esta√ß√£o, exibindo os resultados em uma tabela ordenada por nome da esta√ß√£o.

| station      | min_temperature | mean_temperature | max_temperature |
|--------------|-----------------|------------------|-----------------|
| Abha         | -31.1           | 18.0             | 66.5            |
| Abidjan      | -25.9           | 26.0             | 74.6            |
| Ab√©ch√©       | -19.8           | 29.4             | 79.9            |
| Accra        | -24.8           | 26.4             | 76.3            |
| Addis Ababa  | -31.8           | 16.0             | 63.9            |
| Adelaide     | -31.8           | 17.3             | 71.5            |
| Aden         | -19.6           | 29.1             | 78.3            |
| Ahvaz        | -24.0           | 25.4             | 72.6            |
| Albuquerque  | -35.0           | 14.0             | 61.9            |
| Alexandra    | -40.1           | 11.0             | 67.9            |
| ...          | ...             | ...              | ...             |
| Yangon       | -23.6           | 27.5             | 77.3            |
| Yaound√©      | -26.2           | 23.8             | 73.4            |
| Yellowknife  | -53.4           | -4.3             | 46.7            |
| Yerevan      | -38.6           | 12.4             | 62.8            |
| Yinchuan     | -45.2           | 9.0              | 56.9            |
| Zagreb       | -39.2           | 10.7             | 58.1            |
| Zanzibar City| -26.5           | 26.0             | 75.2            |
| Z√ºrich       | -42.0           | 9.3              | 63.6            |
| √úr√ºmqi       | -42.1           | 7.4              | 56.7            |
| ƒ∞zmir        | -34.4           | 17.9             | 67.9            |

## Depend√™ncias

Para executar os scripts deste projeto, voc√™ precisar√° das seguintes bibliotecas:

* pandas: `^2.2.2`
* duckdb: `^1.0.0`
* dask: `^2024.7.1`
* polars: `^1.3.0`
* fireducks: `^1.2.1`
* streamlit: `^1.37.0`
* Apache Airflow (via Astro CLI)

## Resultados

Os testes foram realizados em um Laptop com Ubuntu 24.04.2 LTS (Lenovo ThinkPad E14 Gen 3) equipado com um processador AMD Ryzen‚Ñ¢ 7 5700U with Radeon‚Ñ¢ Graphics √ó 16 e 16GB de RAM. As implementa√ß√µes utilizaram abordagens puramente Python, Pandas, Dask, Polars, Fireducks e DuckDB. Os resultados de tempo de execu√ß√£o para processar o arquivo de 1 bilh√£o de linhas s√£o apresentados abaixo:

| Implementa√ß√£o | Tempo |
| --- | --- |
| Bash + awk | 25 minutos |
| Python | 20 minutos |
| Python + Pandas | 358.78 seg |
| Python + Fireducks | 324.40 seg |
| Python + Dask | 242.49 seg  |
| Python + Duckdb | 67.78 seg |
| Python + Polars | 36.57 seg |

![arquitetura](/img/podium_1.png)

Obrigado por [Koen Vossen](https://github.com/koenvo) pela implementa√ß√£o em Polars e [Arthur Juli√£o](https://github.com/ArthurJ) pela implementa√ß√£o em Python e Bash 

## Conclus√£o

Este desafio destacou claramente a efic√°cia de diversas bibliotecas Python na manipula√ß√£o de grandes volumes de dados. M√©todos tradicionais como Bash, Python puro e at√© mesmo o Pandas/Fireducks demandaram uma s√©rie de t√°ticas para implementar o processamento em "lotes", enquanto bibliotecas como Dask, Polars e DuckDB provaram ser excepcionalmente eficazes, requerendo menos linhas de c√≥digo devido √† sua capacidade inerente de distribuir os dados em "lotes em streaming" de maneira mais eficiente. 

üèÜ O Polars alcan√ßou o menor tempo de execu√ß√£o (36.57 segundos), talvez devido a uma combina√ß√£o de caracter√≠sticas arquiteturais e estrat√©gias de processamento superiores:
- Lazy Execution: Permite fus√£o de m√∫ltiplas opera√ß√µes em um √∫nico plano otimizado.
- Multi-threading: Aproveita todos os n√∫cleos de CPU dispon√≠veis de forma eficiente.
- Arquitetura em Rust: O c√≥digo base em Rust oferece performance nativa e gerenciamento eficiente de mem√≥ria. Alta performance, mem√≥ria otimizada e paralelismo nativo.

![arquitetura](/img/estrategia_polars.png)

![arquitetura](/img/vantagens_polars.png)

O DuckDB alcan√ßou o segundo menor tempo de execu√ß√£o (67.78 segundos), talvez gra√ßas √† sua estrat√©gia de execu√ß√£o e processamento de dados, que inclui:
1. Query Execution Model:
   - Processamento vetorizado que quebra opera√ß√µes em blocos otimizados
   - Implementa√ß√£o de um otimizador SQL que reduz opera√ß√µes desnecess√°rias
   - Compila√ß√£o interna de queries para acelerar o processamento

2. Processamento de Dados Incremental:
   - Suporte a arquivos Parquet com leitura seletiva de colunas
   - Streaming eficiente de dados, processando blocos de linhas em formato vetorizado
   - Cache inteligente que reutiliza resultados para evitar reprocessamento

3. Multi-threading Eficiente:
   - Aproveitamento autom√°tico de m√∫ltiplos n√∫cleos da CPU
   - Paraleliza√ß√£o inteligente de queries em grandes arquivos
   - Redu√ß√£o significativa do tempo de resposta atrav√©s de execu√ß√£o paralela

![arquitetura](/img/estrategias_processamento_duckdb.png)

![arquitetura](/img/vantagens_duckdb.png)

Esses resultados refor√ßam a import√¢ncia de escolher a ferramenta adequada para an√°lise de dados em larga escala. Polars e DuckDB se destacaram por combinar execu√ß√£o colunar, gerenciamento eficiente de mem√≥ria e paraleliza√ß√£o autom√°tica. O Polars, em particular, demonstrou como uma implementa√ß√£o em Rust com lazy evaluation pode superar significativamente abordagens tradicionais. Isso evidencia que Python, munido das bibliotecas certas, continua sendo uma op√ß√£o poderosa para big data.

## Como Executar

Para executar este projeto e reproduzir os resultados:

1. Clone esse reposit√≥rio
2. Definir a vers√£o do Python usando o `pyenv local 3.12.3`
3. Execute os comandos:
   ```bash
   poetry env use 3.12.3
   poetry install --no-root
   poetry lock --no-update
   ```
4. Execute o comando `python src/create_measurements.py` para gerar o arquivo de teste (caso queira aumentar ou diminuir o tamanho do arquivo, altere o valor da variavel num_rows_to_create=1_000_000_000)
5. Aguarde alguns minutos para a gera√ß√£o completa do arquivo
6. Execute os scripts:
   ```bash
   python src/etl_python.py
   python src/etl_pandas.py
   python src/etl_fireducks.py
   python src/etl_dask.py
   python src/etl_polars.py
   python src/etl_duckdb.py
   ```

## Executando o Apache Airflow

Este projeto utiliza o Apache Airflow para gerenciar e automatizar os fluxos de processamento de dados. Para iniciar o Airflow, siga os passos abaixo:

1. Navegue at√© o diret√≥rio do Airflow:
   ```bash
   cd src/airflow
   ```
2. Inicie o ambiente com Astro CLI:
   ```bash
   astro dev start
   ```
3. Acesse a interface web do Airflow em `http://localhost:8080`
4. Para verificar os DAGs dispon√≠veis e iniciar a execu√ß√£o, ative os DAGs necess√°rios na interface

Caso queira parar a execu√ß√£o do Airflow, utilize:

```bash
astro dev stop
```

## Bonus

Para rodar o script Bash descrito, voc√™ precisa seguir alguns passos simples. Primeiro, assegure-se de que voc√™ tenha um ambiente Unix-like, como Linux ou macOS, que suporta scripts Bash nativamente. Al√©m disso, verifique se as ferramentas utilizadas no script (`wc`, `head`, `pv`, `awk`, e `sort`) est√£o instaladas em seu sistema. A maioria dessas ferramentas vem pr√©-instalada em sistemas Unix-like, mas `pv` (Pipe Viewer) pode precisar ser instalado manualmente.

### Instalando o Pipe Viewer (pv)

Se voc√™ n√£o tem o `pv` instalado, pode facilmente instal√°-lo usando o gerenciador de pacotes do seu sistema. Por exemplo:

* No Ubuntu/Debian:
    
    ```bash
    sudo apt-get update
    sudo apt-get install pv
    ```
    
* No macOS (usando [Homebrew](https://brew.sh/)):
    
    ```bash
    brew install pv
    ```
    
### Preparando o Script

1. D√™ permiss√£o de execu√ß√£o para o arquivo script. Abra um terminal e execute:
    
    ```bash
    chmod +x process_measurements.sh
    ```

2. Rode o script. Abra um terminal e execute:
   
   ```bash
   ./src/using_bash_and_awk.sh 1000
   ```

Neste exemplo, apenas as primeiras 1000 linhas ser√£o processadas.

Ao executar o script, voc√™ ver√° a barra de progresso (se pv estiver instalado corretamente) e, eventualmente, a sa√≠da esperada no terminal ou em um arquivo de sa√≠da, se voc√™ decidir modificar o script para direcionar a sa√≠da.

## Contato

Para d√∫vidas, sugest√µes ou feedbacks:

* **Thiago Silva** - [Linkedin](https://www.linkedin.com/in/thiagosilvafarias/)




